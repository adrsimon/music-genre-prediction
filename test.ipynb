{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.00468</td>\n",
       "      <td>0.652</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.79200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-5.201</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0748</td>\n",
       "      <td>100.889</td>\n",
       "      <td>0.759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.01270</td>\n",
       "      <td>0.622</td>\n",
       "      <td>218.293</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.95000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.124</td>\n",
       "      <td>-7.043</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>115.00200000000001</td>\n",
       "      <td>0.531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.00306</td>\n",
       "      <td>0.620</td>\n",
       "      <td>215.613</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.01180</td>\n",
       "      <td>11</td>\n",
       "      <td>0.534</td>\n",
       "      <td>-4.617</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>127.994</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.0</td>\n",
       "      <td>0.02540</td>\n",
       "      <td>0.774</td>\n",
       "      <td>166.875</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00253</td>\n",
       "      <td>4</td>\n",
       "      <td>0.157</td>\n",
       "      <td>-4.498</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>128.014</td>\n",
       "      <td>0.270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>0.638</td>\n",
       "      <td>222.369</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.90900</td>\n",
       "      <td>9</td>\n",
       "      <td>0.157</td>\n",
       "      <td>-6.266</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0413</td>\n",
       "      <td>145.036</td>\n",
       "      <td>0.323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   popularity  acousticness  danceability  duration_ms  energy  \\\n",
       "0        27.0       0.00468         0.652       -0.001   0.941   \n",
       "1        31.0       0.01270         0.622      218.293   0.890   \n",
       "2        28.0       0.00306         0.620      215.613   0.755   \n",
       "3        34.0       0.02540         0.774      166.875   0.700   \n",
       "4        32.0       0.00465         0.638      222.369   0.587   \n",
       "\n",
       "   instrumentalness  key  liveness  loudness  mode  speechiness  \\\n",
       "0           0.79200    1     0.115    -5.201     1       0.0748   \n",
       "1           0.95000    5     0.124    -7.043     1       0.0300   \n",
       "2           0.01180   11     0.534    -4.617     0       0.0345   \n",
       "3           0.00253    4     0.157    -4.498     0       0.2390   \n",
       "4           0.90900    9     0.157    -6.266     0       0.0413   \n",
       "\n",
       "                tempo  valence  \n",
       "0             100.889    0.759  \n",
       "1  115.00200000000001    0.531  \n",
       "2             127.994    0.333  \n",
       "3             128.014    0.270  \n",
       "4             145.036    0.323  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data/musicgenre.csv')\n",
    "\n",
    "# Handle missing values\n",
    "df = df.dropna(subset=['music_genre'])\n",
    "df = df.replace(\"?\", None).dropna()\n",
    "\n",
    "# Encode categorical features\n",
    "encoder = LabelEncoder()\n",
    "df['music_genre'] = encoder.fit_transform(df['music_genre'])\n",
    "df['key'] = encoder.fit_transform(df['key'])\n",
    "df['mode'] = encoder.fit_transform(df['mode'])\n",
    "df.head()\n",
    "\n",
    "# Scale the features\n",
    "df[\"duration_ms\"] = df[\"duration_ms\"] / 1000\n",
    "\n",
    "# Drop irrelevant columns\n",
    "df.drop(['track_name', 'instance_id', 'obtained_date', 'artist_name'], axis=1, inplace=True)\n",
    "\n",
    "# Split the data into features and target\n",
    "X = df.drop(columns=['music_genre'])\n",
    "y = df['music_genre']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logistic regression: l2 un peu mieux mais change casiment rien"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "afficher la courbe d'apprentissage? training loss validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model\n",
      "Accuracy: 0.5453872353028284\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.34      0.37      1349\n",
      "           1       0.78      0.74      0.76      1349\n",
      "           2       0.60      0.52      0.55      1341\n",
      "           3       0.82      0.85      0.83      1350\n",
      "           4       0.56      0.57      0.57      1346\n",
      "           5       0.64      0.60      0.62      1340\n",
      "           6       0.34      0.36      0.35      1356\n",
      "           7       0.53      0.54      0.53      1356\n",
      "           8       0.32      0.32      0.32      1351\n",
      "           9       0.48      0.62      0.54      1368\n",
      "\n",
      "    accuracy                           0.55     13506\n",
      "   macro avg       0.55      0.55      0.54     13506\n",
      "weighted avg       0.55      0.55      0.54     13506\n",
      "\n",
      "------------------------------------------------------------\n",
      "Logistic Regression Model\n",
      "Accuracy: 0.5221383088997482\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.30      0.34      1349\n",
      "           1       0.61      0.60      0.61      1349\n",
      "           2       0.51      0.45      0.48      1341\n",
      "           3       0.77      0.81      0.79      1350\n",
      "           4       0.44      0.58      0.50      1346\n",
      "           5       0.56      0.57      0.57      1340\n",
      "           6       0.46      0.49      0.48      1356\n",
      "           7       0.48      0.41      0.44      1356\n",
      "           8       0.45      0.36      0.40      1351\n",
      "           9       0.52      0.65      0.58      1368\n",
      "\n",
      "    accuracy                           0.52     13506\n",
      "   macro avg       0.52      0.52      0.52     13506\n",
      "weighted avg       0.52      0.52      0.52     13506\n",
      "\n",
      "------------------------------------------------------------\n",
      "KNN Model\n",
      "Accuracy: 0.47423367392270105\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.35      0.30      1349\n",
      "           1       0.63      0.66      0.64      1349\n",
      "           2       0.48      0.42      0.45      1341\n",
      "           3       0.77      0.81      0.79      1350\n",
      "           4       0.41      0.51      0.45      1346\n",
      "           5       0.59      0.48      0.53      1340\n",
      "           6       0.39      0.44      0.41      1356\n",
      "           7       0.49      0.37      0.42      1356\n",
      "           8       0.34      0.30      0.32      1351\n",
      "           9       0.47      0.42      0.44      1368\n",
      "\n",
      "    accuracy                           0.47     13506\n",
      "   macro avg       0.48      0.47      0.48     13506\n",
      "weighted avg       0.48      0.47      0.48     13506\n",
      "\n",
      "------------------------------------------------------------\n",
      "Decision Tree Model\n",
      "Accuracy: 0.43262253813120094\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.26      0.26      1349\n",
      "           1       0.64      0.63      0.63      1349\n",
      "           2       0.41      0.41      0.41      1341\n",
      "           3       0.75      0.76      0.75      1350\n",
      "           4       0.43      0.42      0.43      1346\n",
      "           5       0.47      0.48      0.48      1340\n",
      "           6       0.30      0.32      0.31      1356\n",
      "           7       0.39      0.40      0.40      1356\n",
      "           8       0.26      0.25      0.26      1351\n",
      "           9       0.42      0.40      0.41      1368\n",
      "\n",
      "    accuracy                           0.43     13506\n",
      "   macro avg       0.43      0.43      0.43     13506\n",
      "weighted avg       0.43      0.43      0.43     13506\n",
      "\n",
      "------------------------------------------------------------\n",
      "Model: Random Forest\n",
      "Accuracy: 0.5453872353028284\n",
      "Classification Report:\n",
      "  0: precision: 0.40, recall: 0.34, f1-score: 0.37, support: 1349.00\n",
      "  1: precision: 0.78, recall: 0.74, f1-score: 0.76, support: 1349.00\n",
      "  2: precision: 0.60, recall: 0.52, f1-score: 0.55, support: 1341.00\n",
      "  3: precision: 0.82, recall: 0.85, f1-score: 0.83, support: 1350.00\n",
      "  4: precision: 0.56, recall: 0.57, f1-score: 0.57, support: 1346.00\n",
      "  5: precision: 0.64, recall: 0.60, f1-score: 0.62, support: 1340.00\n",
      "  6: precision: 0.34, recall: 0.36, f1-score: 0.35, support: 1356.00\n",
      "  7: precision: 0.53, recall: 0.54, f1-score: 0.53, support: 1356.00\n",
      "  8: precision: 0.32, recall: 0.32, f1-score: 0.32, support: 1351.00\n",
      "  9: precision: 0.48, recall: 0.62, f1-score: 0.54, support: 1368.00\n",
      "  macro avg: precision: 0.55, recall: 0.55, f1-score: 0.54, support: 13506.00\n",
      "  weighted avg: precision: 0.55, recall: 0.55, f1-score: 0.54, support: 13506.00\n",
      "------------------------------------------------------------\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.5221383088997482\n",
      "Classification Report:\n",
      "  0: precision: 0.38, recall: 0.30, f1-score: 0.34, support: 1349.00\n",
      "  1: precision: 0.61, recall: 0.60, f1-score: 0.61, support: 1349.00\n",
      "  2: precision: 0.51, recall: 0.45, f1-score: 0.48, support: 1341.00\n",
      "  3: precision: 0.77, recall: 0.81, f1-score: 0.79, support: 1350.00\n",
      "  4: precision: 0.44, recall: 0.58, f1-score: 0.50, support: 1346.00\n",
      "  5: precision: 0.56, recall: 0.57, f1-score: 0.57, support: 1340.00\n",
      "  6: precision: 0.46, recall: 0.49, f1-score: 0.48, support: 1356.00\n",
      "  7: precision: 0.48, recall: 0.41, f1-score: 0.44, support: 1356.00\n",
      "  8: precision: 0.45, recall: 0.36, f1-score: 0.40, support: 1351.00\n",
      "  9: precision: 0.52, recall: 0.65, f1-score: 0.58, support: 1368.00\n",
      "  macro avg: precision: 0.52, recall: 0.52, f1-score: 0.52, support: 13506.00\n",
      "  weighted avg: precision: 0.52, recall: 0.52, f1-score: 0.52, support: 13506.00\n",
      "------------------------------------------------------------\n",
      "Model: KNN\n",
      "Accuracy: 0.47423367392270105\n",
      "Classification Report:\n",
      "  0: precision: 0.26, recall: 0.35, f1-score: 0.30, support: 1349.00\n",
      "  1: precision: 0.63, recall: 0.66, f1-score: 0.64, support: 1349.00\n",
      "  2: precision: 0.48, recall: 0.42, f1-score: 0.45, support: 1341.00\n",
      "  3: precision: 0.77, recall: 0.81, f1-score: 0.79, support: 1350.00\n",
      "  4: precision: 0.41, recall: 0.51, f1-score: 0.45, support: 1346.00\n",
      "  5: precision: 0.59, recall: 0.48, f1-score: 0.53, support: 1340.00\n",
      "  6: precision: 0.39, recall: 0.44, f1-score: 0.41, support: 1356.00\n",
      "  7: precision: 0.49, recall: 0.37, f1-score: 0.42, support: 1356.00\n",
      "  8: precision: 0.34, recall: 0.30, f1-score: 0.32, support: 1351.00\n",
      "  9: precision: 0.47, recall: 0.42, f1-score: 0.44, support: 1368.00\n",
      "  macro avg: precision: 0.48, recall: 0.47, f1-score: 0.48, support: 13506.00\n",
      "  weighted avg: precision: 0.48, recall: 0.47, f1-score: 0.48, support: 13506.00\n",
      "------------------------------------------------------------\n",
      "Model: Decision Tree\n",
      "Accuracy: 0.43262253813120094\n",
      "Classification Report:\n",
      "  0: precision: 0.26, recall: 0.26, f1-score: 0.26, support: 1349.00\n",
      "  1: precision: 0.64, recall: 0.63, f1-score: 0.63, support: 1349.00\n",
      "  2: precision: 0.41, recall: 0.41, f1-score: 0.41, support: 1341.00\n",
      "  3: precision: 0.75, recall: 0.76, f1-score: 0.75, support: 1350.00\n",
      "  4: precision: 0.43, recall: 0.42, f1-score: 0.43, support: 1346.00\n",
      "  5: precision: 0.47, recall: 0.48, f1-score: 0.48, support: 1340.00\n",
      "  6: precision: 0.30, recall: 0.32, f1-score: 0.31, support: 1356.00\n",
      "  7: precision: 0.39, recall: 0.40, f1-score: 0.40, support: 1356.00\n",
      "  8: precision: 0.26, recall: 0.25, f1-score: 0.26, support: 1351.00\n",
      "  9: precision: 0.42, recall: 0.40, f1-score: 0.41, support: 1368.00\n",
      "  macro avg: precision: 0.43, recall: 0.43, f1-score: 0.43, support: 13506.00\n",
      "  weighted avg: precision: 0.43, recall: 0.43, f1-score: 0.43, support: 13506.00\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define the models to test\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=200),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    results[name] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"report\": report\n",
    "    }\n",
    "    print(f\"{name} Model\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# Compare model performance\n",
    "for name, result in results.items():\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"Accuracy: {result['accuracy']}\")\n",
    "    print(\"Classification Report:\")\n",
    "    for label, metrics in result['report'].items():\n",
    "        if isinstance(metrics, dict):\n",
    "            metrics_str = \", \".join([f\"{key}: {value:.2f}\" for key, value in metrics.items()])\n",
    "            print(f\"  {label}: {metrics_str}\")\n",
    "    print(\"-\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
