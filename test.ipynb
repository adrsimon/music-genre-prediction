{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.00468</td>\n",
       "      <td>0.652</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.79200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-5.201</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0748</td>\n",
       "      <td>100.889</td>\n",
       "      <td>0.759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.01270</td>\n",
       "      <td>0.622</td>\n",
       "      <td>218.293</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.95000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.124</td>\n",
       "      <td>-7.043</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>115.00200000000001</td>\n",
       "      <td>0.531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.00306</td>\n",
       "      <td>0.620</td>\n",
       "      <td>215.613</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.01180</td>\n",
       "      <td>11</td>\n",
       "      <td>0.534</td>\n",
       "      <td>-4.617</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>127.994</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.0</td>\n",
       "      <td>0.02540</td>\n",
       "      <td>0.774</td>\n",
       "      <td>166.875</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00253</td>\n",
       "      <td>4</td>\n",
       "      <td>0.157</td>\n",
       "      <td>-4.498</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>128.014</td>\n",
       "      <td>0.270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>0.638</td>\n",
       "      <td>222.369</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.90900</td>\n",
       "      <td>9</td>\n",
       "      <td>0.157</td>\n",
       "      <td>-6.266</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0413</td>\n",
       "      <td>145.036</td>\n",
       "      <td>0.323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   popularity  acousticness  danceability  duration_ms  energy  \\\n",
       "0        27.0       0.00468         0.652       -0.001   0.941   \n",
       "1        31.0       0.01270         0.622      218.293   0.890   \n",
       "2        28.0       0.00306         0.620      215.613   0.755   \n",
       "3        34.0       0.02540         0.774      166.875   0.700   \n",
       "4        32.0       0.00465         0.638      222.369   0.587   \n",
       "\n",
       "   instrumentalness  key  liveness  loudness  mode  speechiness  \\\n",
       "0           0.79200    1     0.115    -5.201     1       0.0748   \n",
       "1           0.95000    5     0.124    -7.043     1       0.0300   \n",
       "2           0.01180   11     0.534    -4.617     0       0.0345   \n",
       "3           0.00253    4     0.157    -4.498     0       0.2390   \n",
       "4           0.90900    9     0.157    -6.266     0       0.0413   \n",
       "\n",
       "                tempo  valence  \n",
       "0             100.889    0.759  \n",
       "1  115.00200000000001    0.531  \n",
       "2             127.994    0.333  \n",
       "3             128.014    0.270  \n",
       "4             145.036    0.323  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data/musicgenre.csv')\n",
    "\n",
    "# Handle missing values\n",
    "df = df.dropna(subset=['music_genre'])\n",
    "df = df.replace(\"?\", None).dropna()\n",
    "\n",
    "# Encode categorical features\n",
    "encoder = LabelEncoder()\n",
    "df['music_genre'] = encoder.fit_transform(df['music_genre'])\n",
    "df['key'] = encoder.fit_transform(df['key'])\n",
    "df['mode'] = encoder.fit_transform(df['mode'])\n",
    "df.head()\n",
    "\n",
    "# Scale the features\n",
    "df[\"duration_ms\"] = df[\"duration_ms\"] / 1000\n",
    "\n",
    "# Drop irrelevant columns\n",
    "df.drop(['track_name', 'instance_id', 'obtained_date', 'artist_name'], axis=1, inplace=True)\n",
    "\n",
    "# Split the data into features and target\n",
    "X = df.drop(columns=['music_genre'])\n",
    "y = df['music_genre']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model\n",
      "Accuracy: 0.5453872353028284\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.34      0.37      1349\n",
      "           1       0.78      0.74      0.76      1349\n",
      "           2       0.60      0.52      0.55      1341\n",
      "           3       0.82      0.85      0.83      1350\n",
      "           4       0.56      0.57      0.57      1346\n",
      "           5       0.64      0.60      0.62      1340\n",
      "           6       0.34      0.36      0.35      1356\n",
      "           7       0.53      0.54      0.53      1356\n",
      "           8       0.32      0.32      0.32      1351\n",
      "           9       0.48      0.62      0.54      1368\n",
      "\n",
      "    accuracy                           0.55     13506\n",
      "   macro avg       0.55      0.55      0.54     13506\n",
      "weighted avg       0.55      0.55      0.54     13506\n",
      "\n",
      "------------------------------------------------------------\n",
      "Logistic Regression Model\n",
      "Accuracy: 0.5221383088997482\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.30      0.34      1349\n",
      "           1       0.61      0.60      0.61      1349\n",
      "           2       0.51      0.45      0.48      1341\n",
      "           3       0.77      0.81      0.79      1350\n",
      "           4       0.44      0.58      0.50      1346\n",
      "           5       0.56      0.57      0.57      1340\n",
      "           6       0.46      0.49      0.48      1356\n",
      "           7       0.48      0.41      0.44      1356\n",
      "           8       0.45      0.36      0.40      1351\n",
      "           9       0.52      0.65      0.58      1368\n",
      "\n",
      "    accuracy                           0.52     13506\n",
      "   macro avg       0.52      0.52      0.52     13506\n",
      "weighted avg       0.52      0.52      0.52     13506\n",
      "\n",
      "------------------------------------------------------------\n",
      "KNN Model\n",
      "Accuracy: 0.47423367392270105\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.35      0.30      1349\n",
      "           1       0.63      0.66      0.64      1349\n",
      "           2       0.48      0.42      0.45      1341\n",
      "           3       0.77      0.81      0.79      1350\n",
      "           4       0.41      0.51      0.45      1346\n",
      "           5       0.59      0.48      0.53      1340\n",
      "           6       0.39      0.44      0.41      1356\n",
      "           7       0.49      0.37      0.42      1356\n",
      "           8       0.34      0.30      0.32      1351\n",
      "           9       0.47      0.42      0.44      1368\n",
      "\n",
      "    accuracy                           0.47     13506\n",
      "   macro avg       0.48      0.47      0.48     13506\n",
      "weighted avg       0.48      0.47      0.48     13506\n",
      "\n",
      "------------------------------------------------------------\n",
      "SVM Model\n",
      "Accuracy: 0.5655264326965793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.37      0.40      1349\n",
      "           1       0.74      0.70      0.72      1349\n",
      "           2       0.60      0.50      0.55      1341\n",
      "           3       0.81      0.84      0.83      1350\n",
      "           4       0.52      0.56      0.54      1346\n",
      "           5       0.63      0.60      0.61      1340\n",
      "           6       0.44      0.54      0.49      1356\n",
      "           7       0.53      0.50      0.52      1356\n",
      "           8       0.44      0.33      0.38      1351\n",
      "           9       0.51      0.71      0.59      1368\n",
      "\n",
      "    accuracy                           0.57     13506\n",
      "   macro avg       0.57      0.57      0.56     13506\n",
      "weighted avg       0.57      0.57      0.56     13506\n",
      "\n",
      "------------------------------------------------------------\n",
      "Gradient Boosting Model\n",
      "Accuracy: 0.5800385014067821\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.39      0.42      1349\n",
      "           1       0.79      0.73      0.76      1349\n",
      "           2       0.63      0.53      0.57      1341\n",
      "           3       0.83      0.83      0.83      1350\n",
      "           4       0.58      0.60      0.59      1346\n",
      "           5       0.67      0.61      0.64      1340\n",
      "           6       0.43      0.46      0.44      1356\n",
      "           7       0.54      0.54      0.54      1356\n",
      "           8       0.41      0.39      0.40      1351\n",
      "           9       0.51      0.72      0.60      1368\n",
      "\n",
      "    accuracy                           0.58     13506\n",
      "   macro avg       0.58      0.58      0.58     13506\n",
      "weighted avg       0.58      0.58      0.58     13506\n",
      "\n",
      "------------------------------------------------------------\n",
      "XGBoost Model\n",
      "Accuracy: 0.5638234858581371\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.38      0.41      1349\n",
      "           1       0.80      0.75      0.77      1349\n",
      "           2       0.62      0.53      0.57      1341\n",
      "           3       0.84      0.84      0.84      1350\n",
      "           4       0.57      0.60      0.58      1346\n",
      "           5       0.66      0.62      0.64      1340\n",
      "           6       0.36      0.38      0.37      1356\n",
      "           7       0.54      0.55      0.54      1356\n",
      "           8       0.35      0.34      0.35      1351\n",
      "           9       0.50      0.65      0.57      1368\n",
      "\n",
      "    accuracy                           0.56     13506\n",
      "   macro avg       0.57      0.56      0.56     13506\n",
      "weighted avg       0.57      0.56      0.56     13506\n",
      "\n",
      "------------------------------------------------------------\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001803 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2660\n",
      "[LightGBM] [Info] Number of data points in the train set: 31514, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -2.304300\n",
      "[LightGBM] [Info] Start training from score -2.303665\n",
      "[LightGBM] [Info] Start training from score -2.309718\n",
      "[LightGBM] [Info] Start training from score -2.303029\n",
      "[LightGBM] [Info] Start training from score -2.306209\n",
      "[LightGBM] [Info] Start training from score -2.310678\n",
      "[LightGBM] [Info] Start training from score -2.298595\n",
      "[LightGBM] [Info] Start training from score -2.298279\n",
      "[LightGBM] [Info] Start training from score -2.302078\n",
      "[LightGBM] [Info] Start training from score -2.289471\n",
      "LightGBM Model\n",
      "Accuracy: 0.5761143195616762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.38      0.41      1349\n",
      "           1       0.80      0.76      0.78      1349\n",
      "           2       0.64      0.52      0.58      1341\n",
      "           3       0.85      0.83      0.84      1350\n",
      "           4       0.59      0.60      0.60      1346\n",
      "           5       0.67      0.63      0.65      1340\n",
      "           6       0.38      0.40      0.39      1356\n",
      "           7       0.54      0.56      0.55      1356\n",
      "           8       0.37      0.38      0.38      1351\n",
      "           9       0.51      0.70      0.59      1368\n",
      "\n",
      "    accuracy                           0.58     13506\n",
      "   macro avg       0.58      0.58      0.58     13506\n",
      "weighted avg       0.58      0.58      0.58     13506\n",
      "\n",
      "------------------------------------------------------------\n",
      "Extra Trees Model\n",
      "Accuracy: 0.5290981785872946\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.32      0.34      1349\n",
      "           1       0.77      0.72      0.74      1349\n",
      "           2       0.57      0.50      0.53      1341\n",
      "           3       0.81      0.85      0.83      1350\n",
      "           4       0.53      0.59      0.55      1346\n",
      "           5       0.63      0.60      0.61      1340\n",
      "           6       0.35      0.39      0.37      1356\n",
      "           7       0.52      0.49      0.51      1356\n",
      "           8       0.31      0.29      0.30      1351\n",
      "           9       0.46      0.55      0.50      1368\n",
      "\n",
      "    accuracy                           0.53     13506\n",
      "   macro avg       0.53      0.53      0.53     13506\n",
      "weighted avg       0.53      0.53      0.53     13506\n",
      "\n",
      "------------------------------------------------------------\n",
      "Decision Tree Model\n",
      "Accuracy: 0.43262253813120094\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.26      0.26      1349\n",
      "           1       0.64      0.63      0.63      1349\n",
      "           2       0.41      0.41      0.41      1341\n",
      "           3       0.75      0.76      0.75      1350\n",
      "           4       0.43      0.42      0.43      1346\n",
      "           5       0.47      0.48      0.48      1340\n",
      "           6       0.30      0.32      0.31      1356\n",
      "           7       0.39      0.40      0.40      1356\n",
      "           8       0.26      0.25      0.26      1351\n",
      "           9       0.42      0.40      0.41      1368\n",
      "\n",
      "    accuracy                           0.43     13506\n",
      "   macro avg       0.43      0.43      0.43     13506\n",
      "weighted avg       0.43      0.43      0.43     13506\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Model\n",
      "Accuracy: 0.48526580778913075\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.18      0.26      1349\n",
      "           1       0.54      0.58      0.56      1349\n",
      "           2       0.57      0.31      0.40      1341\n",
      "           3       0.56      0.91      0.69      1350\n",
      "           4       0.52      0.45      0.48      1346\n",
      "           5       0.56      0.43      0.49      1340\n",
      "           6       0.38      0.25      0.30      1356\n",
      "           7       0.41      0.42      0.42      1356\n",
      "           8       0.39      0.72      0.51      1351\n",
      "           9       0.50      0.60      0.54      1368\n",
      "\n",
      "    accuracy                           0.49     13506\n",
      "   macro avg       0.49      0.49      0.47     13506\n",
      "weighted avg       0.49      0.49      0.47     13506\n",
      "\n",
      "------------------------------------------------------------\n",
      "Model: Random Forest\n",
      "Accuracy: 0.5453872353028284\n",
      "Classification Report:\n",
      "  0: precision: 0.40, recall: 0.34, f1-score: 0.37, support: 1349.00\n",
      "  1: precision: 0.78, recall: 0.74, f1-score: 0.76, support: 1349.00\n",
      "  2: precision: 0.60, recall: 0.52, f1-score: 0.55, support: 1341.00\n",
      "  3: precision: 0.82, recall: 0.85, f1-score: 0.83, support: 1350.00\n",
      "  4: precision: 0.56, recall: 0.57, f1-score: 0.57, support: 1346.00\n",
      "  5: precision: 0.64, recall: 0.60, f1-score: 0.62, support: 1340.00\n",
      "  6: precision: 0.34, recall: 0.36, f1-score: 0.35, support: 1356.00\n",
      "  7: precision: 0.53, recall: 0.54, f1-score: 0.53, support: 1356.00\n",
      "  8: precision: 0.32, recall: 0.32, f1-score: 0.32, support: 1351.00\n",
      "  9: precision: 0.48, recall: 0.62, f1-score: 0.54, support: 1368.00\n",
      "  macro avg: precision: 0.55, recall: 0.55, f1-score: 0.54, support: 13506.00\n",
      "  weighted avg: precision: 0.55, recall: 0.55, f1-score: 0.54, support: 13506.00\n",
      "------------------------------------------------------------\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.5221383088997482\n",
      "Classification Report:\n",
      "  0: precision: 0.38, recall: 0.30, f1-score: 0.34, support: 1349.00\n",
      "  1: precision: 0.61, recall: 0.60, f1-score: 0.61, support: 1349.00\n",
      "  2: precision: 0.51, recall: 0.45, f1-score: 0.48, support: 1341.00\n",
      "  3: precision: 0.77, recall: 0.81, f1-score: 0.79, support: 1350.00\n",
      "  4: precision: 0.44, recall: 0.58, f1-score: 0.50, support: 1346.00\n",
      "  5: precision: 0.56, recall: 0.57, f1-score: 0.57, support: 1340.00\n",
      "  6: precision: 0.46, recall: 0.49, f1-score: 0.48, support: 1356.00\n",
      "  7: precision: 0.48, recall: 0.41, f1-score: 0.44, support: 1356.00\n",
      "  8: precision: 0.45, recall: 0.36, f1-score: 0.40, support: 1351.00\n",
      "  9: precision: 0.52, recall: 0.65, f1-score: 0.58, support: 1368.00\n",
      "  macro avg: precision: 0.52, recall: 0.52, f1-score: 0.52, support: 13506.00\n",
      "  weighted avg: precision: 0.52, recall: 0.52, f1-score: 0.52, support: 13506.00\n",
      "------------------------------------------------------------\n",
      "Model: KNN\n",
      "Accuracy: 0.47423367392270105\n",
      "Classification Report:\n",
      "  0: precision: 0.26, recall: 0.35, f1-score: 0.30, support: 1349.00\n",
      "  1: precision: 0.63, recall: 0.66, f1-score: 0.64, support: 1349.00\n",
      "  2: precision: 0.48, recall: 0.42, f1-score: 0.45, support: 1341.00\n",
      "  3: precision: 0.77, recall: 0.81, f1-score: 0.79, support: 1350.00\n",
      "  4: precision: 0.41, recall: 0.51, f1-score: 0.45, support: 1346.00\n",
      "  5: precision: 0.59, recall: 0.48, f1-score: 0.53, support: 1340.00\n",
      "  6: precision: 0.39, recall: 0.44, f1-score: 0.41, support: 1356.00\n",
      "  7: precision: 0.49, recall: 0.37, f1-score: 0.42, support: 1356.00\n",
      "  8: precision: 0.34, recall: 0.30, f1-score: 0.32, support: 1351.00\n",
      "  9: precision: 0.47, recall: 0.42, f1-score: 0.44, support: 1368.00\n",
      "  macro avg: precision: 0.48, recall: 0.47, f1-score: 0.48, support: 13506.00\n",
      "  weighted avg: precision: 0.48, recall: 0.47, f1-score: 0.48, support: 13506.00\n",
      "------------------------------------------------------------\n",
      "Model: SVM\n",
      "Accuracy: 0.5655264326965793\n",
      "Classification Report:\n",
      "  0: precision: 0.43, recall: 0.37, f1-score: 0.40, support: 1349.00\n",
      "  1: precision: 0.74, recall: 0.70, f1-score: 0.72, support: 1349.00\n",
      "  2: precision: 0.60, recall: 0.50, f1-score: 0.55, support: 1341.00\n",
      "  3: precision: 0.81, recall: 0.84, f1-score: 0.83, support: 1350.00\n",
      "  4: precision: 0.52, recall: 0.56, f1-score: 0.54, support: 1346.00\n",
      "  5: precision: 0.63, recall: 0.60, f1-score: 0.61, support: 1340.00\n",
      "  6: precision: 0.44, recall: 0.54, f1-score: 0.49, support: 1356.00\n",
      "  7: precision: 0.53, recall: 0.50, f1-score: 0.52, support: 1356.00\n",
      "  8: precision: 0.44, recall: 0.33, f1-score: 0.38, support: 1351.00\n",
      "  9: precision: 0.51, recall: 0.71, f1-score: 0.59, support: 1368.00\n",
      "  macro avg: precision: 0.57, recall: 0.57, f1-score: 0.56, support: 13506.00\n",
      "  weighted avg: precision: 0.57, recall: 0.57, f1-score: 0.56, support: 13506.00\n",
      "------------------------------------------------------------\n",
      "Model: Gradient Boosting\n",
      "Accuracy: 0.5800385014067821\n",
      "Classification Report:\n",
      "  0: precision: 0.46, recall: 0.39, f1-score: 0.42, support: 1349.00\n",
      "  1: precision: 0.79, recall: 0.73, f1-score: 0.76, support: 1349.00\n",
      "  2: precision: 0.63, recall: 0.53, f1-score: 0.57, support: 1341.00\n",
      "  3: precision: 0.83, recall: 0.83, f1-score: 0.83, support: 1350.00\n",
      "  4: precision: 0.58, recall: 0.60, f1-score: 0.59, support: 1346.00\n",
      "  5: precision: 0.67, recall: 0.61, f1-score: 0.64, support: 1340.00\n",
      "  6: precision: 0.43, recall: 0.46, f1-score: 0.44, support: 1356.00\n",
      "  7: precision: 0.54, recall: 0.54, f1-score: 0.54, support: 1356.00\n",
      "  8: precision: 0.41, recall: 0.39, f1-score: 0.40, support: 1351.00\n",
      "  9: precision: 0.51, recall: 0.72, f1-score: 0.60, support: 1368.00\n",
      "  macro avg: precision: 0.58, recall: 0.58, f1-score: 0.58, support: 13506.00\n",
      "  weighted avg: precision: 0.58, recall: 0.58, f1-score: 0.58, support: 13506.00\n",
      "------------------------------------------------------------\n",
      "Model: XGBoost\n",
      "Accuracy: 0.5638234858581371\n",
      "Classification Report:\n",
      "  0: precision: 0.44, recall: 0.38, f1-score: 0.41, support: 1349.00\n",
      "  1: precision: 0.80, recall: 0.75, f1-score: 0.77, support: 1349.00\n",
      "  2: precision: 0.62, recall: 0.53, f1-score: 0.57, support: 1341.00\n",
      "  3: precision: 0.84, recall: 0.84, f1-score: 0.84, support: 1350.00\n",
      "  4: precision: 0.57, recall: 0.60, f1-score: 0.58, support: 1346.00\n",
      "  5: precision: 0.66, recall: 0.62, f1-score: 0.64, support: 1340.00\n",
      "  6: precision: 0.36, recall: 0.38, f1-score: 0.37, support: 1356.00\n",
      "  7: precision: 0.54, recall: 0.55, f1-score: 0.54, support: 1356.00\n",
      "  8: precision: 0.35, recall: 0.34, f1-score: 0.35, support: 1351.00\n",
      "  9: precision: 0.50, recall: 0.65, f1-score: 0.57, support: 1368.00\n",
      "  macro avg: precision: 0.57, recall: 0.56, f1-score: 0.56, support: 13506.00\n",
      "  weighted avg: precision: 0.57, recall: 0.56, f1-score: 0.56, support: 13506.00\n",
      "------------------------------------------------------------\n",
      "Model: LightGBM\n",
      "Accuracy: 0.5761143195616762\n",
      "Classification Report:\n",
      "  0: precision: 0.46, recall: 0.38, f1-score: 0.41, support: 1349.00\n",
      "  1: precision: 0.80, recall: 0.76, f1-score: 0.78, support: 1349.00\n",
      "  2: precision: 0.64, recall: 0.52, f1-score: 0.58, support: 1341.00\n",
      "  3: precision: 0.85, recall: 0.83, f1-score: 0.84, support: 1350.00\n",
      "  4: precision: 0.59, recall: 0.60, f1-score: 0.60, support: 1346.00\n",
      "  5: precision: 0.67, recall: 0.63, f1-score: 0.65, support: 1340.00\n",
      "  6: precision: 0.38, recall: 0.40, f1-score: 0.39, support: 1356.00\n",
      "  7: precision: 0.54, recall: 0.56, f1-score: 0.55, support: 1356.00\n",
      "  8: precision: 0.37, recall: 0.38, f1-score: 0.38, support: 1351.00\n",
      "  9: precision: 0.51, recall: 0.70, f1-score: 0.59, support: 1368.00\n",
      "  macro avg: precision: 0.58, recall: 0.58, f1-score: 0.58, support: 13506.00\n",
      "  weighted avg: precision: 0.58, recall: 0.58, f1-score: 0.58, support: 13506.00\n",
      "------------------------------------------------------------\n",
      "Model: Extra Trees\n",
      "Accuracy: 0.5290981785872946\n",
      "Classification Report:\n",
      "  0: precision: 0.36, recall: 0.32, f1-score: 0.34, support: 1349.00\n",
      "  1: precision: 0.77, recall: 0.72, f1-score: 0.74, support: 1349.00\n",
      "  2: precision: 0.57, recall: 0.50, f1-score: 0.53, support: 1341.00\n",
      "  3: precision: 0.81, recall: 0.85, f1-score: 0.83, support: 1350.00\n",
      "  4: precision: 0.53, recall: 0.59, f1-score: 0.55, support: 1346.00\n",
      "  5: precision: 0.63, recall: 0.60, f1-score: 0.61, support: 1340.00\n",
      "  6: precision: 0.35, recall: 0.39, f1-score: 0.37, support: 1356.00\n",
      "  7: precision: 0.52, recall: 0.49, f1-score: 0.51, support: 1356.00\n",
      "  8: precision: 0.31, recall: 0.29, f1-score: 0.30, support: 1351.00\n",
      "  9: precision: 0.46, recall: 0.55, f1-score: 0.50, support: 1368.00\n",
      "  macro avg: precision: 0.53, recall: 0.53, f1-score: 0.53, support: 13506.00\n",
      "  weighted avg: precision: 0.53, recall: 0.53, f1-score: 0.53, support: 13506.00\n",
      "------------------------------------------------------------\n",
      "Model: Decision Tree\n",
      "Accuracy: 0.43262253813120094\n",
      "Classification Report:\n",
      "  0: precision: 0.26, recall: 0.26, f1-score: 0.26, support: 1349.00\n",
      "  1: precision: 0.64, recall: 0.63, f1-score: 0.63, support: 1349.00\n",
      "  2: precision: 0.41, recall: 0.41, f1-score: 0.41, support: 1341.00\n",
      "  3: precision: 0.75, recall: 0.76, f1-score: 0.75, support: 1350.00\n",
      "  4: precision: 0.43, recall: 0.42, f1-score: 0.43, support: 1346.00\n",
      "  5: precision: 0.47, recall: 0.48, f1-score: 0.48, support: 1340.00\n",
      "  6: precision: 0.30, recall: 0.32, f1-score: 0.31, support: 1356.00\n",
      "  7: precision: 0.39, recall: 0.40, f1-score: 0.40, support: 1356.00\n",
      "  8: precision: 0.26, recall: 0.25, f1-score: 0.26, support: 1351.00\n",
      "  9: precision: 0.42, recall: 0.40, f1-score: 0.41, support: 1368.00\n",
      "  macro avg: precision: 0.43, recall: 0.43, f1-score: 0.43, support: 13506.00\n",
      "  weighted avg: precision: 0.43, recall: 0.43, f1-score: 0.43, support: 13506.00\n",
      "------------------------------------------------------------\n",
      "Model: AdaBoost\n",
      "Accuracy: 0.48526580778913075\n",
      "Classification Report:\n",
      "  0: precision: 0.45, recall: 0.18, f1-score: 0.26, support: 1349.00\n",
      "  1: precision: 0.54, recall: 0.58, f1-score: 0.56, support: 1349.00\n",
      "  2: precision: 0.57, recall: 0.31, f1-score: 0.40, support: 1341.00\n",
      "  3: precision: 0.56, recall: 0.91, f1-score: 0.69, support: 1350.00\n",
      "  4: precision: 0.52, recall: 0.45, f1-score: 0.48, support: 1346.00\n",
      "  5: precision: 0.56, recall: 0.43, f1-score: 0.49, support: 1340.00\n",
      "  6: precision: 0.38, recall: 0.25, f1-score: 0.30, support: 1356.00\n",
      "  7: precision: 0.41, recall: 0.42, f1-score: 0.42, support: 1356.00\n",
      "  8: precision: 0.39, recall: 0.72, f1-score: 0.51, support: 1351.00\n",
      "  9: precision: 0.50, recall: 0.60, f1-score: 0.54, support: 1368.00\n",
      "  macro avg: precision: 0.49, recall: 0.49, f1-score: 0.47, support: 13506.00\n",
      "  weighted avg: precision: 0.49, recall: 0.49, f1-score: 0.47, support: 13506.00\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define the models to test\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"SVM\": SVC(probability=True),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss'),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=42),\n",
    "    \"Extra Trees\": ExtraTreesClassifier(random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    results[name] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"report\": report\n",
    "    }\n",
    "    print(f\"{name} Model\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# Compare model performance\n",
    "for name, result in results.items():\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"Accuracy: {result['accuracy']}\")\n",
    "    print(\"Classification Report:\")\n",
    "    for label, metrics in result['report'].items():\n",
    "        if isinstance(metrics, dict):\n",
    "            metrics_str = \", \".join([f\"{key}: {value:.2f}\" for key, value in metrics.items()])\n",
    "            print(f\"  {label}: {metrics_str}\")\n",
    "    print(\"-\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
